
# coding: utf-8

# In[6]:

from BeautifulSoup import BeautifulSoup
import urllib,string,csv,sys,os


# In[7]:

page_count = 2
page = ''
fx_url_s = 'http://en.artron.net/auction/paimai-list.php?page='
fx_url_e = '&zcid=PZ2012759&o=0'


# In[35]:

def get_tables(url_s,url_e,total_page):
    for p in range(1,total_page+1):
        url = url_s+str(p)+url_e
        data = urllib.urlopen(url).read()
        soup = BeautifulSoup(data)
        
        tables = soup.findAll("table")
        depth3 = []
        for t in tables:
            if len(t.findParents("table")) == 3:
                depth3.append(t)
        print depth3
        #file = open("artron_data.csv","a")
        #file.write(data)
    #file.close()


# In[36]:

get_tables(fx_url_s,fx_url_e,page_count)


# In[ ]:



